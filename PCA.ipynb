{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "PCA.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7o9CK_Af6DY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "# load dataset into Pandas DataFrame\n",
        "df = pd.read_csv(url, names=['sepal length','sepal width','petal length','petal width','target'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dprCAmjOf6Db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "features = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
        "# Separating out the features\n",
        "x = df.loc[:, features].values\n",
        "# Separating out the target\n",
        "y = df.loc[:,['target']].values\n",
        "# Standardizing the features\n",
        "x = StandardScaler().fit_transform(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtMHW-37f6Dd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dacb5828-338a-42b0-f50a-03dc7c9e6386"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "principalComponents = pca.fit_transform(x)\n",
        "principalDf = pd.DataFrame(data = principalComponents\n",
        "             , columns = ['principal component 1', 'principal component 2'])\n",
        "print(principalDf)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     principal component 1  principal component 2\n",
            "0                -2.264542               0.505704\n",
            "1                -2.086426              -0.655405\n",
            "2                -2.367950              -0.318477\n",
            "3                -2.304197              -0.575368\n",
            "4                -2.388777               0.674767\n",
            "5                -2.070537               1.518549\n",
            "6                -2.445711               0.074563\n",
            "7                -2.233842               0.247614\n",
            "8                -2.341958              -1.095146\n",
            "9                -2.188676              -0.448629\n",
            "10               -2.163487               1.070596\n",
            "11               -2.327378               0.158587\n",
            "12               -2.224083              -0.709118\n",
            "13               -2.639716              -0.938282\n",
            "14               -2.192292               1.889979\n",
            "15               -2.251465               2.722371\n",
            "16               -2.202750               1.513750\n",
            "17               -2.190179               0.514304\n",
            "18               -1.894074               1.431111\n",
            "19               -2.339949               1.158033\n",
            "20               -1.914556               0.430465\n",
            "21               -2.204645               0.952457\n",
            "22               -2.774170               0.489517\n",
            "23               -1.820412               0.106751\n",
            "24               -2.228217               0.162186\n",
            "25               -1.957024              -0.607893\n",
            "26               -2.052063               0.266014\n",
            "27               -2.168194               0.552016\n",
            "28               -2.140306               0.336640\n",
            "29               -2.268790              -0.314879\n",
            "..                     ...                    ...\n",
            "120               2.040496               0.907399\n",
            "121               0.973915              -0.571174\n",
            "122               2.898064               0.397791\n",
            "123               1.329194              -0.486761\n",
            "124               1.704241               1.014148\n",
            "125               1.957728               1.003335\n",
            "126               1.171905              -0.318897\n",
            "127               1.019781               0.065543\n",
            "128               1.786009              -0.193273\n",
            "129               1.864778               0.555382\n",
            "130               2.435497               0.246654\n",
            "131               2.316082               2.626184\n",
            "132               1.860371              -0.184672\n",
            "133               1.111272              -0.295986\n",
            "134               1.197469              -0.817168\n",
            "135               2.800949               0.844748\n",
            "136               1.580155               1.072474\n",
            "137               1.347044               0.422256\n",
            "138               0.923433               0.019230\n",
            "139               1.853552               0.672423\n",
            "140               2.016157               0.610397\n",
            "141               1.903117               0.686025\n",
            "142               1.153190              -0.701326\n",
            "143               2.043308               0.864685\n",
            "144               2.001691               1.048550\n",
            "145               1.870522               0.382822\n",
            "146               1.558492              -0.905314\n",
            "147               1.520845               0.266795\n",
            "148               1.376391               1.016362\n",
            "149               0.959299              -0.022284\n",
            "\n",
            "[150 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYZA-G0Ef6Df",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "e6c7d852-ae58-4fc2-fa26-525eefd68a9e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
        "dataset = pd.read_csv(url, names=names)\n",
        "X = dataset.drop('Class', 1)\n",
        "y = dataset['Class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "pca = PCA()\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "print(\"Variance ratio for each component \\n\")\n",
        "print(explained_variance)\n",
        "\n",
        "#using 1 principal component\n",
        "pca = PCA(n_components=1)\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "classifier.fit(X_train, y_train)\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "ans=accuracy_score(y_test, y_pred)\n",
        "print(\"The Accuracy is\")\n",
        "print(ans)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variance ratio for each component \n",
            "\n",
            "[0.72226528 0.23974795 0.03338117 0.0046056 ]\n",
            "[[11  0  0]\n",
            " [ 0 12  1]\n",
            " [ 0  1  5]]\n",
            "The Accuracy is\n",
            "0.9333333333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_CLcfhYf6Dh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "07cf4679-44bb-47de-89aa-2b3a38a2e329"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df.dropna(how=\"all\", inplace=True)\n",
        "X = df.iloc[:,0:4].values\n",
        "y = df.iloc[:,4].values\n",
        "X_std = StandardScaler().fit_transform(X)\n",
        "print('Covariance matrix: \\n%s' %np.cov(X_std.T))\n",
        "cov_mat = np.cov(X_std.T)\n",
        "\n",
        "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
        "\n",
        "print('Eigen vectors \\n%s' %eig_vecs)\n",
        "print('\\nEigen values \\n%s' %eig_vals)\n",
        "for ev in eig_vecs:\n",
        "    np.testing.assert_array_almost_equal(1.0, np.linalg.norm(ev))\n",
        "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
        "\n",
        "eig_pairs.sort()\n",
        "eig_pairs.reverse()\n",
        "\n",
        "print('Eigenvalues in descending order:')\n",
        "for i in eig_pairs:\n",
        "    print(i[0])\n",
        "\n",
        "tot = sum(eig_vals)\n",
        "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
        "cum_var_exp = np.cumsum(var_exp)\n",
        "\n",
        "trace1 = dict(\n",
        "    type='bar',\n",
        "    x=['PC %s' %i for i in range(1,5)],\n",
        "    y=var_exp,\n",
        "    name='Individual'\n",
        ")\n",
        "\n",
        "trace2 = dict(\n",
        "    type='scatter',\n",
        "    x=['PC %s' %i for i in range(1,5)], \n",
        "    y=cum_var_exp,\n",
        "    name='Cumulative'\n",
        ")\n",
        "\n",
        "data = [trace1, trace2]\n",
        "\n",
        "layout=dict(\n",
        "    title='Explained variance by different principal components',\n",
        "    yaxis=dict(\n",
        "        title='Explained variance in percent'\n",
        "    ),\n",
        "    annotations=list([\n",
        "        dict(\n",
        "            x=1.16,\n",
        "            y=1.05,\n",
        "            xref='paper',\n",
        "            yref='paper',\n",
        "            text='Explained Variance',\n",
        "            showarrow=False,\n",
        "        )\n",
        "    ])\n",
        ")\n",
        "matrix_w = np.hstack((eig_pairs[0][1].reshape(4,1), \n",
        "                      eig_pairs[1][1].reshape(4,1)))\n",
        "\n",
        "print('Matrix :\\n', matrix_w)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Covariance matrix: \n",
            "[[ 1.00671141 -0.11010327  0.87760486  0.82344326]\n",
            " [-0.11010327  1.00671141 -0.42333835 -0.358937  ]\n",
            " [ 0.87760486 -0.42333835  1.00671141  0.96921855]\n",
            " [ 0.82344326 -0.358937    0.96921855  1.00671141]]\n",
            "Eigen vectors \n",
            "[[ 0.52237162 -0.37231836 -0.72101681  0.26199559]\n",
            " [-0.26335492 -0.92555649  0.24203288 -0.12413481]\n",
            " [ 0.58125401 -0.02109478  0.14089226 -0.80115427]\n",
            " [ 0.56561105 -0.06541577  0.6338014   0.52354627]]\n",
            "\n",
            "Eigen values \n",
            "[2.93035378 0.92740362 0.14834223 0.02074601]\n",
            "Eigenvalues in descending order:\n",
            "2.930353775589317\n",
            "0.9274036215173419\n",
            "0.14834222648163944\n",
            "0.02074601399559593\n",
            "Matrix :\n",
            " [[ 0.52237162 -0.37231836]\n",
            " [-0.26335492 -0.92555649]\n",
            " [ 0.58125401 -0.02109478]\n",
            " [ 0.56561105 -0.06541577]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FT8sCYXgE7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}